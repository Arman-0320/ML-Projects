{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XkGj8nC_eRkx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms.functional as F\n",
        "import torchvision.transforms as T\n",
        "\n",
        "\n",
        "plt.rcParams[\"savefig.bbox\"] = \"tight\"\n",
        "# sphinx_gallery_thumbnail_number = 2\n",
        "\n",
        "\n",
        "def plot(imgs, **imshow_kwargs):\n",
        "    if not isinstance(imgs[0], list):\n",
        "        # Make a 2d grid even if there's just 1 row\n",
        "        imgs = [imgs]\n",
        "\n",
        "    num_rows = len(imgs)\n",
        "    num_cols = len(imgs[0])\n",
        "    _, axs = plt.subplots(nrows=num_rows, ncols=num_cols, squeeze=False)\n",
        "    for row_idx, row in enumerate(imgs):\n",
        "        for col_idx, img in enumerate(row):\n",
        "            ax = axs[row_idx, col_idx]\n",
        "            img = F.to_pil_image(img.to(\"cpu\"))\n",
        "            ax.imshow(np.asarray(img), **imshow_kwargs)\n",
        "            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "from pathlib import Path\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "\n",
        "# video_url = \"https://download.pytorch.org/tutorial/pexelscom_pavel_danilyuk_basketball_hd.mp4\"\n",
        "video_path = \"/content/vid1.mp4\""
      ],
      "metadata": {
        "id": "pxUSNh-IeZPD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install av\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkJfhmu6IvR_",
        "outputId": "b0f0302d-6f75-4b72-c4cc-69ca01d9855e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting av\n",
            "  Downloading av-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: av\n",
            "Successfully installed av-12.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJbMCrRWVWs3",
        "outputId": "0f1a3f88-9feb-4a56-9036-7eb5791e88c8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(batch):\n",
        "    transforms = T.Compose(\n",
        "        [\n",
        "            T.ConvertImageDtype(torch.float32),\n",
        "            T.Normalize(mean=0.5, std=0.5),  # map [0, 1] into [-1, 1]\n",
        "            T.Resize(size=(520, 960)),\n",
        "        ]\n",
        "    )\n",
        "    batch = transforms(batch)\n",
        "    return batch\n",
        "\n",
        "\n",
        "# If you can, run this example on a GPU, it will be a lot faster.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "g9BViWc0ewAr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def writeFlow(name, flow):\n",
        "    f = open(name, 'wb')\n",
        "    f.write('PIEH'.encode('utf-8'))\n",
        "    np.array([flow.shape[1], flow.shape[0]], dtype=np.int32).tofile(f)\n",
        "    flow = flow.astype(np.float32)\n",
        "    flow.tofile(f)"
      ],
      "metadata": {
        "id": "L6OAVava7Sg2"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readFlow(name):\n",
        "    #if name.endswith('.pfm') or name.endswith('.PFM'):\n",
        "        #return readPFM(name)[0][:,:,0:2]\n",
        "\n",
        "    f = open(name, 'rb')\n",
        "\n",
        "    header = f.read(4)\n",
        "    if header.decode(\"utf-8\") != 'PIEH':\n",
        "        raise Exception('Flow file header does not contain PIEH')\n",
        "\n",
        "    width = np.fromfile(f, np.int32, 1).squeeze()\n",
        "    height = np.fromfile(f, np.int32, 1).squeeze()\n",
        "\n",
        "    flow = np.fromfile(f, np.float32, width * height * 2).reshape((height, width, 2))\n",
        "\n",
        "    return flow.astype(np.float32)"
      ],
      "metadata": {
        "id": "W9C__OS82HIk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import misc\n",
        "def writeImage(name, data):\n",
        "    #if name.endswith('.pfm') or name.endswith('.PFM'):\n",
        "        #return writePFM(name, data, 1)\n",
        "\n",
        "    return misc.imsave(name, data)\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "sL-7tQCk9Hn9"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.io import read_video\n",
        "from torchvision.models.optical_flow import raft_small\n",
        "\n",
        "frames, _, _ = read_video(str(video_path))\n",
        "frames = frames.permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n",
        "ctr = 0\n",
        "\n",
        "for j in range(24):\n",
        "  video_path = f\"/content/drive/MyDrive/Expt5/training_videos/vid{j+1}.mp4\"\n",
        "  for i in range(149):\n",
        "    ctr = ctr+1\n",
        "    frame_list1 = [frames[i]]\n",
        "    frame_list2 = [frames[i+1]]\n",
        "    img1_batch = torch.stack(frame_list1)\n",
        "    img2_batch = torch.stack(frame_list2)\n",
        "    img1_batch = preprocess(img1_batch).to(device)\n",
        "    img2_batch = preprocess(img2_batch).to(device)\n",
        "    model = raft_small(pretrained=True, progress=False).to(device)\n",
        "    model = model.eval()\n",
        "\n",
        "    list_of_flows = model(img1_batch.to(device), img2_batch.to(device))\n",
        "    tensor = list_of_flows[11][0]\n",
        "    tensor = tensor.permute(1,2,0)\n",
        "    file_path = f\"/content/drive/MyDrive/Expt5/train/{ctr}_flow.flo\"\n",
        "    writeFlow(file_path,tensor.detach().numpy())\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "jvFBrk_7OvPu"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "ctr = 0\n",
        "for j in range(24):\n",
        "  video_path = f\"/content/drive/MyDrive/Expt5/training_videos/vid{j+1}.mp4\"\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "  if not cap.isOpened():\n",
        "        print(\"Error: Could not open video file.\")\n",
        "\n",
        "  for i in range(149):\n",
        "    ctr = ctr+1\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "            print(\"Error\")\n",
        "    frame_path = f\"/content/drive/MyDrive/Expt5/train_img1/{ctr}_img1.ppm\"\n",
        "    if not cv2.imwrite(frame_path, frame):\n",
        "      print(f\"Error: {i} frame in {j+1} video\")\n",
        "\n",
        "  cap.release()"
      ],
      "metadata": {
        "id": "KDL6A4I3PvO9"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "ctr = 0\n",
        "for j in range(24):\n",
        "  video_path = f\"/content/drive/MyDrive/Expt5/training_videos/vid{j+1}.mp4\"\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "  if not cap.isOpened():\n",
        "        print(\"Error: Could not open video file.\")\n",
        "\n",
        "  for i in range(1,150):\n",
        "    ctr = ctr+1\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "            print(\"Error\")\n",
        "    frame_path = f\"/content/drive/MyDrive/Expt5/train/{ctr}_img2.ppm\"\n",
        "    if not cv2.imwrite(frame_path, frame):\n",
        "      print(f\"Error: {i} frame in {j+1} video\")\n",
        "\n",
        "  cap.release()"
      ],
      "metadata": {
        "id": "-sX0O2elT8aG"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.io import read_video\n",
        "from torchvision.models.optical_flow import raft_small\n",
        "\n",
        "frames, _, _ = read_video(str(video_path))\n",
        "frames = frames.permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n",
        "ctr = 0\n",
        "\n",
        "for j in range(6):\n",
        "  video_path = f\"/content/drive/MyDrive/Expt5/testing_videos/vid{j+1}.mp4\"\n",
        "  for i in range(149):\n",
        "    ctr = ctr+1\n",
        "    frame_list1 = [frames[i]]\n",
        "    frame_list2 = [frames[i+1]]\n",
        "    img1_batch = torch.stack(frame_list1)\n",
        "    img2_batch = torch.stack(frame_list2)\n",
        "    img1_batch = preprocess(img1_batch).to(device)\n",
        "    img2_batch = preprocess(img2_batch).to(device)\n",
        "    model = raft_small(pretrained=True, progress=False).to(device)\n",
        "    model = model.eval()\n",
        "\n",
        "    list_of_flows = model(img1_batch.to(device), img2_batch.to(device))\n",
        "    tensor = list_of_flows[11][0]\n",
        "    tensor = tensor.permute(1,2,0)\n",
        "    file_path = f\"/content/drive/MyDrive/Expt5/test/{ctr}_flow.flo\"\n",
        "    writeFlow(file_path,tensor.detach().numpy())"
      ],
      "metadata": {
        "id": "N_lbBywLe9xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "ctr = 0\n",
        "for j in range(24):\n",
        "  video_path = f\"/content/drive/MyDrive/Expt5/testing_videos/vid{j+1}.mp4\"\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "  if not cap.isOpened():\n",
        "        print(\"Error: Could not open video file.\")\n",
        "\n",
        "  for i in range(149):\n",
        "    ctr = ctr+1\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "            print(\"Error\")\n",
        "    frame_path = f\"/content/drive/MyDrive/Expt5/test/{ctr}_img1.ppm\"\n",
        "    if not cv2.imwrite(frame_path, frame):\n",
        "      print(f\"Error: {i} frame in {j+1} video\")\n",
        "\n",
        "  cap.release()"
      ],
      "metadata": {
        "id": "1qqZvYgcfFKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "ctr = 0\n",
        "for j in range(24):\n",
        "  video_path = f\"/content/drive/MyDrive/Expt5/training_videos/vid{j+1}.mp4\"\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "  if not cap.isOpened():\n",
        "        print(\"Error: Could not open video file.\")\n",
        "\n",
        "  for i in range(1,150):\n",
        "    ctr = ctr+1\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "            print(\"Error\")\n",
        "    frame_path = f\"/content/drive/MyDrive/Expt5/test/{ctr}_img2.ppm\"\n",
        "    if not cv2.imwrite(frame_path, frame):\n",
        "      print(f\"Error: {i} frame in {j+1} video\")\n",
        "\n",
        "  cap.release()"
      ],
      "metadata": {
        "id": "ikdUtp4_fN_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list_of_flows[11].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjMPcNkhnxNf",
        "outputId": "9b9376af-f057-4e37-8cb1-f9c8f95abc4a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 2, 520, 960])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = '22862_flow.flo'\n",
        "flow_array = readFlow(file_name)\n",
        "print(flow_array.shape)\n",
        "print(flow_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiFc5pvE2MnG",
        "outputId": "d8ec34c3-7e5d-4d24-b905-a28de1ec3dc6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(384, 512, 2)\n",
            "[[[-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]\n",
            "  ...\n",
            "  [-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]]\n",
            "\n",
            " [[-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]\n",
            "  ...\n",
            "  [-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]]\n",
            "\n",
            " [[-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]\n",
            "  ...\n",
            "  [-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]\n",
            "  ...\n",
            "  [-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]]\n",
            "\n",
            " [[-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]\n",
            "  ...\n",
            "  [-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]]\n",
            "\n",
            " [[-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]\n",
            "  ...\n",
            "  [-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]\n",
            "  [-16.585667  12.283061]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = list_of_flows[11][0]\n",
        "print(tensor.shape)\n",
        "tensor = tensor.permute(1,2,0)\n",
        "print(tensor.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKSkzf4-3XBC",
        "outputId": "55737ee3-3404-4efc-a9c3-ab1b5f2589f4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 520, 960])\n",
            "torch.Size([520, 960, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "writeFlow('flow.flo',tensor.detach().numpy())"
      ],
      "metadata": {
        "id": "Qws0JLOY7T0p"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}